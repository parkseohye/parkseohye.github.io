## **First to Tenth Steps in Statistics** 

Recommendation **:** 【Statistics】 [Statistics Overview](https://jb243.github.io/1641-01-01-1641.html)

Kim, S.K., Park, J.B. (2022) FESTBOOK MEDIA. 979-11-92302-44-7 95410 (2nd ed)

---

<br>
<center>
<img src="https://user-images.githubusercontent.com/55747737/198064954-da157310-ea57-4d3e-b731-789b2bf62460.png" alt="drawing" style="width:400px;"/>
</center>
  <br>


AlphaGo appeared in this world through a historic Go match in 2016. The implication of AlphaGo's existence is that first, we can understand the world with black boxes, and second, we can "abbreviate" the vast amount of information around us with deep learning algorithms.

<br>

Regarding the first implication:
Pre-AlphaGo science took a hypothesis-based approach based on Karl Popper's rebuttalism. However, after AlphaGo, you can generate hypotheses from data, verify hypotheses from data, and you don't even need hypotheses from data. For example, biology was previously recognized as a human-centered teleological study, but thanks to the emergence of bioinformatics, attempts are being made to interpret biology as data itself.
 
 <br>

 
With respect to the second implication:
The current rate at which information is generated is breathtaking. Economists saw that in less than 50 years, knowledge would build up faster than understanding it. In this case, artificial intelligence that far exceeds human perception may be born around a pile of data. An algorithm to "compress" vast amounts of information is needed to prevent that singularity, and we expect deep learning algorithms to play a role.
 
 <br>
 
AlphaGo is, after all, no less than a flood of data. In this case, you'll need to study statistics, which is a study that deals with data, and to help you with this, I've summarized the statistics situation so far.
